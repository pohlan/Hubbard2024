{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95ac7741-ef22-41e1-b027-74d90da19e73",
   "metadata": {},
   "source": [
    "# Construct surface elevation time series along the centerline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf0e484-f4ea-454b-8a6e-651b7f0c946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm.auto import tqdm\n",
    "import xesmf as xe\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point, LineString\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e14df-d051-4d3d-baa4-3d56228e9e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Define paths to data\n",
    "data_path = '/Users/raineyaberle/Research/PhD/Hubbard/'\n",
    "figures_out_path = os.path.join(data_path, 'figures')\n",
    "h_out_path = os.path.join(data_path, 'surface_elevation')\n",
    "\n",
    "# -----Load bed data\n",
    "bed_fn = os.path.join(data_path, 'bed_topo', 'hubbard_bedrock_icebridge.tif')\n",
    "bed = rxr.open_rasterio(bed_fn)\n",
    "\n",
    "# -----Load coregistered DEMs and rasterized ICESat-2 file names\n",
    "h_fns = sorted(glob.glob(os.path.join(data_path, 'surface_elevation', 'surface_elevation_filtered_old', '*.tif')))\n",
    "\n",
    "# -----Load IFSAR DEM\n",
    "ifsar_fn = 'ifsar_hubbardDEM.tif'\n",
    "ifsar = xr.open_dataset(os.path.join(data_path, 'surface_elevation', ifsar_fn))\n",
    "# adjust dimensions\n",
    "h = ifsar.band_data.data[0]\n",
    "ifsar = ifsar.drop_dims('band')\n",
    "ifsar['h'] = (('y', 'x'), h)\n",
    "# Downsample to 20 m resolution\n",
    "ifsar = ifsar.coarsen(x=4, y=4, boundary='pad').mean()\n",
    "\n",
    "# -----Plot IFSAR DEM and bed topo\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12,6))\n",
    "ifsar_im = ax[0].imshow(ifsar['h'], cmap='viridis',\n",
    "           extent=(np.min(ifsar.x.data)/1e3, np.max(ifsar.x.data)/1e3, \n",
    "                   np.min(ifsar.y.data)/1e3, np.max(ifsar.y.data)/1e3))\n",
    "ax[0].set_xlabel('Easting [km]')\n",
    "ax[0].set_ylabel('Northing [km]')\n",
    "ax[0].set_title('IFSAR DEM')\n",
    "fig.colorbar(ifsar_im, ax=ax[0], shrink=0.7, label='meters')\n",
    "bed_im = ax[1].imshow(bed.data[0], cmap='Greys', \n",
    "                      extent=(np.min(bed.x.data)/1e3, np.max(bed.x.data)/1e3,\n",
    "                              np.min(bed.y.data)/1e3, np.max(bed.y.data)/1e3))\n",
    "ax[1].set_xlabel('Easting [km]')\n",
    "ax[1].set_title('Bed topography')\n",
    "fig.colorbar(bed_im, ax=ax[1], shrink=0.7, label='meters')\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da30ca-3df2-4acc-befb-354273088c0c",
   "metadata": {},
   "source": [
    "## Interpolate the surface and bed along the centerline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64d61e4-eefe-4039-b560-aad56df6798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_linestring_resolution(line, distance=50):\n",
    "    # calculate initial distance vector\n",
    "    x, y = line.coords.xy[0], line.coords.xy[1]\n",
    "    line_dist = np.zeros(len(line.coords.xy[0]))\n",
    "    for i in range(1, len(line.coords.xy[0])):\n",
    "        line_dist[i] = np.sqrt((x[i]-x[i-1])**2 + (y[i]-y[i-1])**2) + line_dist[i-1]\n",
    "        \n",
    "    # create new line distance vector\n",
    "    new_line_dist = np.arange(0, np.nanmax(line_dist), step=distance)\n",
    "\n",
    "    # interpolate coordinates on new distance vector\n",
    "    new_x = np.interp(new_line_dist, line_dist, x)\n",
    "    new_y = np.interp(new_line_dist, line_dist, y)\n",
    "\n",
    "    # save as linestring\n",
    "    new_coords = list(zip(new_x, new_y))\n",
    "    new_line = LineString(new_coords)\n",
    "    \n",
    "    return new_line, new_line_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95161ac1-e0e8-42d2-8d2c-850fd859f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load centerline\n",
    "cl_path = os.path.join(data_path, 'velocity', 'center.gpkg')\n",
    "cl = gpd.read_file(cl_path)\n",
    "# Reproject to Alaska Albers\n",
    "cl = cl.to_crs('EPSG:3338')\n",
    "# Increase spatial resolution\n",
    "new_geom, cl_dist = increase_linestring_resolution(cl.geometry[0])\n",
    "cl['geometry'] = [new_geom]\n",
    "# Create distance along centerline vector\n",
    "cl_x, cl_y = cl.geometry[0].coords.xy[0], cl.geometry[0].coords.xy[1]\n",
    "# Sample bed data along centerline\n",
    "cl_bed = [bed.sel(x=x, y=y, method='nearest').data[0] for x, y in zip(cl_x, cl_y)]\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "bed_im = ax.imshow(bed.data[0], cmap='Greys', \n",
    "                      extent=(np.min(bed.x.data), np.max(bed.x.data),\n",
    "                              np.min(bed.y.data), np.max(bed.y.data)))\n",
    "ax.set_xlabel('Easting [km]')\n",
    "ax.set_ylabel('Northing [km]')\n",
    "cl.plot(ax=ax, color='m', label='Centerline')\n",
    "ax.legend(loc='upper left')\n",
    "fig.colorbar(bed_im, ax=ax, label='Bed topography [m]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8576b10-54ed-4a8d-8e9b-f709e3335ce7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----Sample surface elevations from DEMs\n",
    "# Check if sampled elevations already exist in file\n",
    "h_cl_fn = os.path.join(data_path, 'surface_elevation', 'centerline_surface_elevation_timeseries.csv')\n",
    "if os.path.exists(h_cl_fn):\n",
    "    h_cl_df = pd.read_csv(h_cl_fn)\n",
    "    dates = pd.to_datetime(h_cl_df['Date'])\n",
    "    datasets = h_cl_df['Dataset']\n",
    "    h_cl = h_cl_df.iloc[:,2:].values\n",
    "    print('Centerline surface profiles loaded from file.')\n",
    "\n",
    "else:\n",
    "    \n",
    "    # Initialize centerline surface heights\n",
    "    h_cl = np.zeros((len(h_fns), len(cl.geometry[0].coords.xy[0])))\n",
    "    dates = []\n",
    "    datasets = []\n",
    "    \n",
    "    # Iterate over file names\n",
    "    for i, fn in enumerate(h_fns):\n",
    "        h_xda = rxr.open_rasterio(fn)\n",
    "        dates.append(os.path.basename(fn)[0:10])\n",
    "        datasets.append(os.path.basename(fn).split('_')[1])\n",
    "        h_cl[i,:] = [h_xda.sel(x=x, y=y, method='nearest').data[0] for x,y in zip(cl_x, cl_y)]\n",
    "    \n",
    "    # Convert dates to datetimes\n",
    "    dts = pd.DatetimeIndex([np.datetime64(date) for date in dates])\n",
    "    \n",
    "    # Remove wacky elevation values\n",
    "    h_cl[np.abs(h_cl) > 1e4] = np.nan\n",
    "\n",
    "    # Reformat as DataFrame and save to file\n",
    "    h_cl_df = pd.DataFrame({'Date': dates,\n",
    "                            'Dataset': datasets})\n",
    "    for i in range(np.shape(h_cl)[1]):\n",
    "        df = pd.DataFrame({str(cl_dist[i]): h_cl[:,i]})\n",
    "        h_cl_df = pd.concat([h_cl_df, df], axis=1)\n",
    "    \n",
    "    h_cl_df.to_csv(h_cl_fn, index=False)\n",
    "    print('Centerline surface elevations saved to file:', h_cl_fn)\n",
    "\n",
    "h_cl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8429f8fc-9d6a-4593-95f3-d3052da6365e",
   "metadata": {},
   "source": [
    "## Smooth the elevation profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10036636-381b-4665-b3ee-0a7ff80fb5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Check if smoothed surface profiles already exist in directory\n",
    "h_cl_smooth_fn = os.path.join(data_path, 'surface_elevation', 'centerline_surface_elevation_timeseries_smooth.csv')\n",
    "if os.path.exists(h_cl_smooth_fn):\n",
    "    h_cl_smooth_df = pd.read_csv(h_cl_smooth_fn)\n",
    "    h_cl_smooth = h_cl_smooth_df.iloc[:,2:].values\n",
    "    print('Smoothed surface profiles loaded from file.')\n",
    "\n",
    "else:\n",
    "\n",
    "    # Smooth each elevation profile\n",
    "    def moving_average_smoothing(arr, window_size=5):\n",
    "        smoothed_arr = np.zeros_like(arr)\n",
    "        for i in range(arr.shape[0]):\n",
    "            smoothed_arr[i, :] = np.convolve(arr[i, :], np.ones(window_size) / window_size, mode='same')\n",
    "        return smoothed_arr\n",
    "    h_cl_smooth = moving_average_smoothing(h_cl)\n",
    "    h_cl_smooth[h_cl_smooth==0] = np.nan\n",
    "    \n",
    "    # Reformat as DataFrame and save to file\n",
    "    h_cl_smooth_df = pd.DataFrame({'Date': dates,\n",
    "                                   'Dataset': datasets})\n",
    "    for i in range(np.shape(h_cl_smooth)[1]):\n",
    "        df = pd.DataFrame({str(cl_dist[i]): h_cl_smooth[:,i]})\n",
    "        h_cl_smooth_df = pd.concat([h_cl_smooth_df, df], axis=1)\n",
    "    \n",
    "    h_cl_smooth_df.to_csv(h_cl_smooth_fn, index=False)\n",
    "    print('Smoothed centerline surface elevations saved to file:', h_cl_smooth_fn)\n",
    "\n",
    "h_cl_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6544c2c-45ed-48b0-82aa-d28a9d868028",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dece8d-5bd6-4699-ad01-0b59a339743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine whether to plot smoothed or raw surface elevations\n",
    "smoothed = True\n",
    "\n",
    "plt.rcParams.update({'font.size':12, 'font.sans-serif':'Arial'})\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8,8), layout='constrained', \n",
    "                       gridspec_kw={'height_ratios':[1.5, 1]})\n",
    "lw=1.5\n",
    "\n",
    "# Define colormap for surface profiles\n",
    "cmap = plt.cm.twilight\n",
    "\n",
    "# plot bed topo\n",
    "ax[0].plot(cl_dist, cl_bed, '-k', label='Bed topography')\n",
    "ax[1].plot(cl_dist, cl_bed, '-k', label='Bed topography')\n",
    "\n",
    "for i in range(len(h_fns)):\n",
    "    month = pd.DatetimeIndex(h_cl_df['Date']).month[i]\n",
    "    color = cmap((month-1)/11)\n",
    "    if smoothed:\n",
    "        ax[0].plot(cl_dist, h_cl_smooth[i,:], '-', linewidth=lw, color=color)\n",
    "        ax[1].plot(cl_dist, h_cl_smooth[i,:], '-', linewidth=lw, color=color)\n",
    "    else:\n",
    "        ax[0].plot(cl_dist, h_cl[i,:], '-', linewidth=lw, color=color)\n",
    "        ax[1].plot(cl_dist, h_cl[i,:], '-', linewidth=lw, color=color)\n",
    "\n",
    "# Plot zoom in box on first panel\n",
    "xmin, xmax = 6e3, 16e3\n",
    "ymin, ymax = 150, 550\n",
    "ax[0].plot([xmin, xmax, xmax, xmin, xmin], [ymin, ymin, ymax, ymax, ymin], '--k')\n",
    "\n",
    "# Plot the colorbar\n",
    "sm = ScalarMappable(cmap=cmap)\n",
    "cbar = fig.colorbar(sm, ax=ax[0], location='top')\n",
    "cbar.ax.set_xticks(np.linspace(0,1,num=12))\n",
    "cbar.ax.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'June', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "\n",
    "# Adjust axes\n",
    "ax[0].legend(loc='lower left')\n",
    "ax[0].grid()\n",
    "ax[0].set_ylabel('Elevation [m]')\n",
    "ax[0].set_xlim(5e3, cl_dist[-1])\n",
    "ax[0].set_ylim(-500, 700)\n",
    "ax[0]\n",
    "ax[1].grid()\n",
    "ax[1].set_xlabel('Distance along centerline [m]')\n",
    "ax[1].set_ylabel('Elevation [m]')\n",
    "ax[1].set_xlim(xmin, xmax)\n",
    "ax[1].set_ylim(ymin, ymax)\n",
    "\n",
    "# Add labels to panels\n",
    "ax[0].text((ax[0].get_xlim()[1] - ax[0].get_xlim()[0]) * 0.95 + ax[0].get_xlim()[0],\n",
    "           (ax[0].get_ylim()[1] - ax[0].get_ylim()[0]) * 0.9 + ax[0].get_ylim()[0],\n",
    "           'a', fontweight='bold', fontsize=14, bbox=dict(facecolor='w', edgecolor='None', pad=5))\n",
    "ax[1].text((ax[1].get_xlim()[1] - ax[1].get_xlim()[0]) * 0.95 + ax[1].get_xlim()[0],\n",
    "           (ax[1].get_ylim()[1] - ax[1].get_ylim()[0]) * 0.85 + ax[1].get_ylim()[0],\n",
    "           'b', fontweight='bold', fontsize=14, bbox=dict(facecolor='w', edgecolor='None', pad=5))\n",
    "# Barcode plot of dates with elevation observations\n",
    "# dts = pd.DatetimeIndex(dates)\n",
    "# for dt in dts:\n",
    "#     ax[2].plot([dt, dt], [0,1], '-k', linewidth=1)\n",
    "# ax[2].set_yticks([])\n",
    "# ax[2].set_xlim(np.datetime64('2009-01-01'), np.datetime64('2023-01-01'))\n",
    "# ax[2].set_ylim(0,1)\n",
    "# ax[2].set_title('Dates with surface observations')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save figure\n",
    "if smoothed:\n",
    "    fig_fn = os.path.join(figures_out_path, 'centerline_surface_elevations_smooth.png')\n",
    "else:\n",
    "    fig_fn = os.path.join(figures_out_path, 'centerline_surface_elevations.png')\n",
    "fig.savefig(fig_fn, dpi=300)\n",
    "print('Figure saved to file:', fig_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81a47ce-390b-495e-a9db-08a0a98e15be",
   "metadata": {},
   "source": [
    "## Assess how many observations each dataset is contributing to the elevation profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c44c00-6378-4870-874c-5c6fb4864b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = h_cl_df['Dataset'].drop_duplicates().values\n",
    "obs_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    h_cl_dataset = h_cl_df.loc[h_cl_df['Dataset']==dataset]\n",
    "    \n",
    "    obs = h_cl_dataset.drop(['Date', 'Dataset'], axis=1).values\n",
    "    nobs=len(obs[~np.isnan(obs)])\n",
    "    df = pd.DataFrame({'Dataset': [dataset], 'Obs.': [nobs]})\n",
    "    obs_df = pd.concat([obs_df, df])\n",
    "obs_df.reset_index(drop=True)\n",
    "obs_df.plot.bar(x='Dataset', y='Obs.', legend=False)\n",
    "plt.title('Number of centerline elevations per dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faddf75a-9d9b-47a2-9ede-f2dc9b4115b0",
   "metadata": {},
   "source": [
    "## Plot elevation anomalies from median over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813b5b9-dc37-4a12-95b7-6d8fad143546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Grab filtered surface elevation file names\n",
    "# h_out_fns = sorted(glob.glob(os.path.join(h_out_path, '*.tif')))\n",
    "# print('Loading and concatenating DEMs...')\n",
    "# i=0\n",
    "# for h_out_fn in tqdm(h_out_fns):\n",
    "#     # Grab date from file name\n",
    "#     date = os.path.basename(h_out_fn).split('_')[0]\n",
    "#     # Load DEM\n",
    "#     h_xda = rxr.open_rasterio(h_out_fn)\n",
    "#     # Convert to xarray.Dataset\n",
    "#     h_xda = h_xda.expand_dims(time=[np.datetime64(date)])\n",
    "#     h_xds_date = h_xda.to_dataset(dim='band')\n",
    "#     h_xds_date = h_xds_date.rename({1:'surface_elevation'})\n",
    "#     # Concatenate to full dataset\n",
    "#     if i==0:\n",
    "#         h_xds = h_xds_date.copy()\n",
    "#     else:\n",
    "#         h_xds = xr.concat([h_xds, h_xds_date], dim='time')\n",
    "#     i+=1\n",
    "\n",
    "# # Subtract the spatial median\n",
    "# h_diff_xds = h_xds - h_xds.median(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e062ae-4e15-4100-9079-a756ee694a3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Plot over time\n",
    "# for i in range(len(h_diff_xds.time.data)):\n",
    "#     h_diff_date_xds = h_diff_xds.isel(time=i)\n",
    "#     date = h_diff_xds.time.data[i]\n",
    "#     fig, ax = plt.subplots()\n",
    "#     h_diff_im = ax.imshow(h_diff_date_xds['surface_elevation'].data, cmap=plt.cm.RdBu, clim=(-20, 20),\n",
    "#                           extent=(np.min(h_diff_date_xds.x.data)/1e3, np.max(h_diff_date_xds.x.data)/1e3,\n",
    "#                                   np.min(h_diff_date_xds.y.data)/1e3, np.max(h_diff_date_xds.y.data)/1e3))\n",
    "#     ax.set_xlabel('Easting [km]')\n",
    "#     ax.set_ylabel('Northing [km]')\n",
    "#     ax.set_title(str(date)[0:10])\n",
    "#     fig.colorbar(h_diff_im, ax=ax, label='Elevation anomaly [m]')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bc88b0-d1cd-4fc9-9fbd-8163fe3f6025",
   "metadata": {},
   "source": [
    "## Calculate surface elevation anomalies over time with respect to IFSAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe4b71a-1258-4777-a182-dbe3bc98189a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Grab filtered surface elevation file names\n",
    "# h_out_fns = sorted(glob.glob(os.path.join(h_out_path, '*.tif')))\n",
    "# # Iterate over file names\n",
    "# i=0\n",
    "# for h_out_fn in tqdm(h_out_fns):\n",
    "#     # Grab date from file name\n",
    "#     date = os.path.basename(h_out_fn).split('_')[0]\n",
    "#     # Load DEM\n",
    "#     h_xda = rxr.open_rasterio(h_out_fn)\n",
    "#     # Subtract IFSAR elevations\n",
    "#     h_xda = h_xda - ifsar['h'].data\n",
    "#     # Convert to xarray.Dataset\n",
    "#     h_xda = h_xda.expand_dims(time=[np.datetime64(date)])\n",
    "#     h_diff_date = h_xda.to_dataset(dim='band')\n",
    "#     h_diff_date = h_diff_date.rename({1:'surface_elevation_diff_from_IFSAR'})\n",
    "#     # Add dataset dimension\n",
    "#     if 'ArcticDEM' in os.path.basename(h_out_fn):\n",
    "#         dataset = 'ArcticDEM'\n",
    "#     elif 'OIB' in os.path.basename(h_out_fn):\n",
    "#         dataset = 'OIB'\n",
    "#     elif 'ICESat-2' in os.path.basename(h_out_fn):\n",
    "#         dataset = 'ICESat-2'\n",
    "#     h_diff_date = h_diff_date.assign_coords(dataset=dataset)\n",
    "#     # Concatenate to full dataset\n",
    "#     if i==0:\n",
    "#         h_diff = h_diff_date.copy()\n",
    "#     else:\n",
    "#         h_diff = xr.concat([h_diff, h_diff_date], dim='time')\n",
    "#     i+=1\n",
    "# h_diff = h_diff.rio.write_crs('EPSG:3338')\n",
    "# h_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1949574a-d322-4f89-94b3-eeabe90c4951",
   "metadata": {},
   "source": [
    "## Extract surface elevation anomalies in polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04dca1f-c0e0-4c45-9c1d-6175a830db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select gates to grab anomalies\n",
    "# from shapely.geometry import Polygon, LineString\n",
    "# xmin1, xmax1 = 806e3, 809.5e3\n",
    "# ymin1, ymax1 = 1.210e6, 1.214e6\n",
    "# poly1 = Polygon([[xmin1, ymin1], [xmax1, ymin1],\n",
    "#                  [xmax1, ymax1], [xmin1, ymax1], [xmin1, ymin1]])\n",
    "# xmin2, xmax2 = 803e3, 806e3\n",
    "# ymin2, ymax2 = 1.203e6, 1.207e6\n",
    "# poly2 = Polygon([[xmin2, ymin2], [xmax2, ymin2],\n",
    "#                  [xmax2, ymax2], [xmin2, ymax2], [xmin2, ymin2]])\n",
    "\n",
    "# # plot\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(ifsar['h'], cmap='Greys_r', clim=(0,1500),\n",
    "#           extent=(np.min(ifsar.x.data)/1e3, np.max(ifsar.x.data)/1e3,\n",
    "#                   np.min(ifsar.y.data)/1e3, np.max(ifsar.y.data)/1e3))\n",
    "# ax.plot(np.divide(poly1.exterior.coords.xy[0], 1e3), \n",
    "#         np.divide(poly1.exterior.coords.xy[1], 1e3), \n",
    "#         '-', linewidth=2)\n",
    "# ax.plot(np.divide(poly2.exterior.coords.xy[0], 1e3), \n",
    "#         np.divide(poly2.exterior.coords.xy[1], 1e3),\n",
    "#         '-', linewidth=2)\n",
    "# ax.set_xlabel('Easting [km]')\n",
    "# ax.set_ylabel('Northing [km]')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39057917-8dfc-4734-9c2d-1894d9e853ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Interpolate thickness anomalies in polygons\n",
    "# h_diff_poly1 = h_diff.rio.clip([poly1]).surface_elevation_diff_from_IFSAR.median(dim=['x', 'y'], skipna=True).data\n",
    "# h_diff_poly2 = h_diff.rio.clip([poly2]).surface_elevation_diff_from_IFSAR.median(dim=['x', 'y'], skipna=True).data\n",
    "# datasets = h_diff.dataset.data\n",
    "\n",
    "# # Compile in dataframe\n",
    "# diffs_df = pd.DataFrame({'Date': h_diff.time.data,\n",
    "#                          'Dataset': datasets,\n",
    "#                          'median_diff_upglacier': h_diff_poly1,\n",
    "#                          'median_diff_downglacier': h_diff_poly2})\n",
    "# for col in ['median_diff_upglacier', 'median_diff_downglacier']:\n",
    "#     diffs_df.loc[np.abs(diffs_df[col]) > 30, col] = np.nan\n",
    "# diffs_df.set_index('Date', inplace=True)\n",
    "\n",
    "# # Add date columns\n",
    "# diffs_df['year'] = pd.DatetimeIndex(diffs_df.index).year\n",
    "# diffs_df['month'] = pd.DatetimeIndex(diffs_df.index).month\n",
    "# diffs_df['WOY'] = pd.DatetimeIndex(diffs_df.index).isocalendar().week\n",
    "# diffs_df['DOY'] = pd.DatetimeIndex(diffs_df.index).dayofyear\n",
    "\n",
    "# diffs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d6de4-1596-408f-b921-1f0795679e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----Plot\n",
    "# # define colors\n",
    "# poly1_col = 'b'\n",
    "# poly2_col = 'c'\n",
    "# # figure settings\n",
    "# lw = 1.5 # line width\n",
    "# ms = 10 # marker size\n",
    "# marker_dict = {'ArcticDEM': 'o',\n",
    "#                'OIB': 's',\n",
    "#                'ICESat-2': '^'}\n",
    "\n",
    "# plt.rcParams.update({'font.sans-serif': 'Arial', 'font.size': 12})\n",
    "# fig, ax = plt.subplots(2, 2, figsize=(10,8), gridspec_kw={'width_ratios': [1, 2]})\n",
    "# ax = ax.flatten()\n",
    "# # IFSAR map\n",
    "# ifsar_im = ax[0].imshow(ifsar['h'], cmap='Greys_r', clim=(0,1200), \n",
    "#              extent=(np.min(ifsar.x.data)/1e3, np.max(ifsar.x.data)/1e3,\n",
    "#                      np.min(ifsar.y.data)/1e3, np.max(ifsar.y.data)/1e3))\n",
    "# ax[0].plot(np.divide(poly1.exterior.coords.xy[0], 1e3), np.divide(poly1.exterior.coords.xy[1], 1e3),\n",
    "#            '-', color=poly1_col, linewidth=2)\n",
    "# ax[0].plot(np.divide(poly2.exterior.coords.xy[0], 1e3), np.divide(poly2.exterior.coords.xy[1], 1e3),\n",
    "#            '-', color=poly2_col, linewidth=2)\n",
    "# ax[0].set_xticklabels([])\n",
    "# ax[0].set_yticklabels([])\n",
    "# fig.colorbar(ifsar_im, ax=ax[0], shrink=0.6, label='Elevation [m]', orientation='horizontal')\n",
    "# ax[0].set_title('IFSAR')\n",
    "# ax[0].set_xlim(790, 810)\n",
    "# ax[0].set_ylim(1200, 1220)\n",
    "# for column, color in zip(['median_diff_upglacier', 'median_diff_downglacier'], [poly1_col, poly2_col]):\n",
    "#     # Full time series\n",
    "#     sns.scatterplot(data=diffs_df, x='Date', y=column, color=color, style='Dataset', \n",
    "#                     markers=marker_dict, ax=ax[1], legend=False)\n",
    "#     # Monthly \n",
    "#     sns.scatterplot(data=diffs_df, x='month', y=column, style='Dataset', \n",
    "#                     markers=marker_dict, color=color, legend=False)\n",
    "#     ax[3].plot(diffs_df.groupby(by='month')[column].median().index,\n",
    "#                diffs_df.groupby(by='month')[column].median(), \n",
    "#                '-', color=color, linewidth=lw)\n",
    "\n",
    "\n",
    "# ax[1].set_ylabel('meters')\n",
    "# ax[1].grid()\n",
    "# ax[1].set_ylim(0, 30)\n",
    "# ax[3].set_ylabel('meters')\n",
    "# ax[3].set_ylim(0, 30)\n",
    "# ax[3].grid()\n",
    "# # plot dummy points for legend\n",
    "# for dataset, marker in zip(marker_dict.keys(), marker_dict.values()):\n",
    "#     ax[3].plot(-10, -10, marker, markersize=ms, color='k', label=dataset)\n",
    "# ax[3].plot(-10, -10, '-k', linewidth=lw, label='Monthly median')\n",
    "# handles, labels = ax[3].get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='lower left', bbox_to_anchor=[0.07, 0.3, 0.3, 0.3])\n",
    "# ax[3].set_xlim(0, 13)\n",
    "# ax[3].set_xticks(np.arange(1,13))\n",
    "# ax[3].set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "#                        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "# ax[2].remove()\n",
    "    \n",
    "# fig.suptitle('Surface elevation difference from IFSAR DEM')\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # save figure\n",
    "# fig_fn = os.path.join(figures_out_path, 'surface_elevation_anomaly_regions_datasets.png')\n",
    "# fig.savefig(fig_fn, dpi=250, bbox_inches='tight')\n",
    "# print('Figure saved to file:', fig_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78266358-7d51-438c-a1ee-bf088d1915a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot with colors distinguishing years\n",
    "\n",
    "# fig, ax = plt.subplots(3, 2, figsize=(12,10), gridspec_kw={'width_ratios': [1,2]})\n",
    "# ax = ax.flatten()\n",
    "# # IFSAR map\n",
    "# ifsar_im = ax[0].imshow(ifsar['h'], cmap='Greys_r', clim=(0,1200), \n",
    "#              extent=(np.min(ifsar.x.data)/1e3, np.max(ifsar.x.data)/1e3,\n",
    "#                      np.min(ifsar.y.data)/1e3, np.max(ifsar.y.data)/1e3))\n",
    "# ax[0].plot(np.divide(poly1.exterior.coords.xy[0], 1e3), np.divide(poly1.exterior.coords.xy[1], 1e3),\n",
    "#            '-', color=poly1_col, linewidth=2)\n",
    "# ax[0].plot(np.divide(poly2.exterior.coords.xy[0], 1e3), np.divide(poly2.exterior.coords.xy[1], 1e3),\n",
    "#            '-', color=poly2_col, linewidth=2)\n",
    "# ax[0].set_xticklabels([])\n",
    "# ax[0].set_yticklabels([])\n",
    "# fig.colorbar(ifsar_im, ax=ax[0], shrink=0.6, label='Elevation [m]', orientation='horizontal')\n",
    "# ax[0].set_title('IFSAR')\n",
    "# ax[0].set_xlim(790, 810)\n",
    "# ax[0].set_ylim(1200, 1220)\n",
    "# # Upglacier\n",
    "# up_im = sns.scatterplot(data=diffs_df, x='month', y='median_diff_upglacier', style='Dataset', \n",
    "#                         markers=marker_dict, hue='year', palette='viridis', ax=ax[1])\n",
    "# ax[1].set_title('Upglacier')\n",
    "# ax[1].grid()\n",
    "# sns.move_legend(up_im, loc='lower left', bbox_to_anchor=[-0.55, -1.5, 0.2, 0.2])\n",
    "# ax[1].set_xticks(np.arange(1,13))\n",
    "# ax[1].set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "#                        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "# ax[1].set_xlabel('')\n",
    "# # Downglacier\n",
    "# sns.scatterplot(data=diffs_df, x='month', y='median_diff_downglacier', style='Dataset', \n",
    "#                 markers=marker_dict, hue='year', palette='viridis', ax=ax[3], legend=False)\n",
    "# ax[3].set_xlabel('')\n",
    "# ax[3].set_xticks(np.arange(1,13))\n",
    "# ax[3].set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "#                        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "# ax[3].set_title('Downglacier')\n",
    "# ax[3].grid()\n",
    "# # Upglacier - downglacier\n",
    "# diffs_df['median_diff_upglacier-downglacier'] = diffs_df['median_diff_upglacier'] - diffs_df['median_diff_downglacier']\n",
    "# # for i, year in enumerate(diffs_df['year'].drop_duplicates().values):\n",
    "# #     diffs_year = diffs_df.loc[diffs_df['year']==year]\n",
    "# #     ax[5].plot(diffs_year['month'], diffs_year['median_diff_upglacier-downglacier'], \n",
    "# #                '.-', color=plt.cm.viridis(i/len(diffs_df['year'].drop_duplicates().values)))\n",
    "# sns.scatterplot(data=diffs_df, x='month', y='median_diff_upglacier-downglacier', style='Dataset', \n",
    "#                 markers=marker_dict, hue='year', palette='viridis', ax=ax[5], legend=False)\n",
    "# ax[5].set_xlabel('Month')\n",
    "# ax[5].set_xticks(np.arange(1,13))\n",
    "# ax[5].set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "#                        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "# ax[5].grid()\n",
    "# ax[5].set_title('Upglacier - Downglacier')\n",
    "\n",
    "# for axis in [ax[1], ax[3], ax[5]]:\n",
    "#     axis.set_ylabel('meters')\n",
    "# ax[2].remove()\n",
    "# ax[4].remove()\n",
    "# fig.subplots_adjust(hspace=0.3)\n",
    "# plt.show()\n",
    "\n",
    "# # Save figure\n",
    "# fig_fn = os.path.join(figures_out_path, 'surface_elevation_anomaly_regions_years.png')\n",
    "# fig.savefig(fig_fn, dpi=250, bbox_inches='tight')\n",
    "# print('Figure saved to file:', fig_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac498c-3955-4e1c-9d06-b264ddabd755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# # sample surface anomalies along centerline\n",
    "# cl_diffs = np.array([h_diff.sel(x=x.coords.xy[0][0], y=x.coords.xy[1][0], method='nearest').surface_elevation_diff_from_IFSAR.data \n",
    "#                      for x in cl_gpd.geometry])\n",
    "# cl_diffs[np.abs(cl_diffs) > 100] = np.nan\n",
    "\n",
    "# # Smooth\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12,6))\n",
    "# for i in range(len(h_diff.time.data)):\n",
    "#     ax.plot(np.divide(cl_gpd['cngmeters'], 1e3), cl_diffs[:,i], \n",
    "#             '-', color=plt.cm.viridis(i/len(h_diff.time.data)), label=h_diff.time.data[i])\n",
    "# # ax.legend()\n",
    "# ax.set_xlabel('Distance along centerline [km]')\n",
    "# ax.set_ylabel('Elevation difference w.r.t. IFSAR')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b60dd72-d69a-4934-863d-09e0d544b450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hubbard",
   "language": "python",
   "name": "hubbard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a058745d-0ed6-4847-b75d-7caeb7528411",
   "metadata": {},
   "source": [
    "# Calculate some cross-correlations in time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64769615-8877-41e5-91df-c02c91f594f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "from scipy.signal import correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953a9c43-75e4-43a6-be06-d06260c063c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/raineyaberle/Research/PhD/Hubbard/'\n",
    "figures_out_path = os.path.join(data_path, 'figures')\n",
    "\n",
    "# Load velocity\n",
    "v_fn = os.path.join(data_path, 'velocity', 'hubbard_inversion_2015-10-01_2023-01-01.nc')\n",
    "v = xr.open_dataset(v_fn)\n",
    "v = v.rio.write_crs('EPSG:3413')\n",
    "v = v.rio.reproject('EPSG:3338') # reproject to Alaska Albers\n",
    "v['v'] = np.sqrt(v['vx']**2 + v['vy']**2) \n",
    "\n",
    "# Load terminus\n",
    "term_sections_fn = os.path.join(data_path, 'terminus', 'terminus_sections.gpkg')\n",
    "term_sections = gpd.read_file(term_sections_fn)\n",
    "term_sections = term_sections.to_crs('EPSG:3338') # reproject to Alaska Albers\n",
    "term_fn = os.path.join(data_path, 'terminus', 'terminus_position_smooth.csv')\n",
    "term = pd.read_csv(term_fn)\n",
    "term['Date'] = pd.to_datetime(term['Date'])\n",
    "term.set_index('Date', inplace=True)\n",
    "\n",
    "# Load weather data\n",
    "weather_fn = os.path.join(data_path, 'weather', 'compiled_weather_data_PDDs.csv')\n",
    "weather = pd.read_csv(weather_fn)\n",
    "weather.rename(columns={'Unnamed: 0': 'Date'}, inplace=True)\n",
    "weather['Date'] = pd.to_datetime(weather['Date'])\n",
    "weather.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0299f30-9b9c-4651-bb51-3272e84da6f2",
   "metadata": {},
   "source": [
    "## By terminus segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ed4c4-2403-4668-9a43-322c6f89fe92",
   "metadata": {},
   "source": [
    "### Velocity-Terminus X-corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc70c64-ed45-47ad-8e44-412a05aa861b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up figure\n",
    "plt.rcParams.update({'font.size': 14, 'font.sans-serif': 'Arial'})\n",
    "fig, ax = plt.subplots(5, 2, gridspec_kw={'width_ratios': [1.5,1]}, figsize=(14, 20))\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Resample terminus positions at equal time spacing\n",
    "term_resamp = term.resample('2W').median()\n",
    "t = np.array(term_resamp.index)\n",
    "# Iterate over terminus sections\n",
    "for i, geom in enumerate(term_sections.geometry[0:-1]):\n",
    "    # clip v to terminus section\n",
    "    v_clip = v.rio.clip([geom], term_sections.crs)\n",
    "    # calculate median velocity in terminus section\n",
    "    v_clip_median = v_clip.median(dim=['x', 'y']).v.data\n",
    "    # resample velocity in time\n",
    "    v_clip_median_resamp = np.interp(t.astype(float), v.time.data.astype(float), v_clip_median)\n",
    "    # de-mean\n",
    "    v_clip_median_resamp_demean = v_clip_median_resamp - np.nanmean(v_clip_median_resamp)\n",
    "    term_values = -1 * (term_resamp[term_resamp.columns[i]] - np.nanmean(term_resamp[term_resamp.columns[i]]))\n",
    "    # plot time series\n",
    "    ax[i*2].plot(t, v_clip_median_resamp, '-b')\n",
    "    ax[i*2].set_title(term_resamp.columns[i].replace(' [m]', ''))\n",
    "    ax[i*2].set_ylabel('Velocity, de-meaned [m/y]', color='b')\n",
    "    ax[i*2].spines.left.set_color('b')\n",
    "    ax[i*2].tick_params(axis='y', colors='b')\n",
    "    ax2 = ax[i*2].twinx()\n",
    "    ax2.plot(t, term_values, '-m')\n",
    "    ax2.set_ylabel('Terminus retreat, de-meaned [m]', color='m')\n",
    "    ax2.spines.right.set_color('m')\n",
    "    ax2.tick_params(axis='y', colors='m')    \n",
    "    # calculate cross-correlation for each year\n",
    "    years = np.unique(t.astype('datetime64[Y]').astype(int) + 1970)\n",
    "    for j, year in enumerate(years):\n",
    "        # subset time series to year\n",
    "        df = pd.DataFrame(term_values.loc[term_values.index.year == year])\n",
    "        t_v = t.astype('datetime64[Y]').astype(int) + 1970\n",
    "        Ivyear = np.ravel(np.argwhere(t_v == year))\n",
    "        df['v'] = v_clip_median_resamp_demean[Ivyear]\n",
    "        df.dropna(inplace=True)\n",
    "        # calculate Xcorr(v, term)\n",
    "        xcorr = correlate(df.values[:,1], df.values[:,0], mode='full', method='auto')\n",
    "        t_xcorr = (np.arange(0,len(xcorr)) * 2)\n",
    "        t_xcorr = t_xcorr - np.mean(t_xcorr)\n",
    "        # plot X-corr\n",
    "        color = plt.cm.viridis(j/(len(years)-1))\n",
    "        ax[i*2+1].plot(t_xcorr, xcorr, '-', color=color, label=str(year))\n",
    "        ax[i*2+1].set_xlabel('Weeks')\n",
    "        ax[i*2+1].set_ylabel('X-corr')\n",
    "        ax[i*2+1].legend(loc='lower left', bbox_to_anchor=[1.0, 0.2, 0.2, 0.2])\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "plt.show()\n",
    "\n",
    "# save figure\n",
    "fig_fn = os.path.join(figures_out_path, 'xcorr_velocity_terminus.png')\n",
    "fig.savefig(fig_fn, dpi=300, bbox_inches='tight')\n",
    "print('Figure saved to file:', fig_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15adc89-170a-407f-b16c-f7f950a71fd0",
   "metadata": {},
   "source": [
    "### Velocity-Weather X-corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275475b-6f68-4169-a5b0-67142655d4f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define columns to use\n",
    "columns = ['PDD_Haenke1', 'Precip_Yakutat']\n",
    "column_names = ['PDD', 'precipitation']\n",
    "\n",
    "# resample at weekly intervals\n",
    "weather = weather.resample('1W').mean()\n",
    "t = np.array(weather.index)\n",
    "\n",
    "# Iterate over weather columns\n",
    "for column, column_name in zip(columns, column_names):\n",
    "    # Set up figure\n",
    "    plt.rcParams.update({'font.size': 14, 'font.sans-serif': 'Arial'})\n",
    "    fig, ax = plt.subplots(5, 2, gridspec_kw={'width_ratios': [1.5,1]}, figsize=(16, 20))\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    # subset weather df to column\n",
    "    weather_column = weather[column]\n",
    "    # Iterate over terminus sections\n",
    "    for i, geom in enumerate(term_sections.geometry[0:-1]):\n",
    "        # clip v to terminus section\n",
    "        v_clip = v.rio.clip([geom], term_sections.crs)\n",
    "        # calculate median velocity in terminus section\n",
    "        v_clip_median = v_clip.median(dim=['x', 'y']).v.data\n",
    "        # resample velocity in time\n",
    "        v_clip_median_resamp = np.interp(t.astype(float), v.time.data.astype(float), v_clip_median)\n",
    "        # de-mean\n",
    "        v_clip_median_resamp_demean = v_clip_median_resamp - np.nanmean(v_clip_median_resamp)\n",
    "        weather_column = weather_column - np.nanmean(weather_column)\n",
    "        # plot time series\n",
    "        ax[i*2].plot(t, v_clip_median_resamp, '-b')\n",
    "        ax[i*2].set_title(term_sections.section[i])\n",
    "        ax[i*2].set_ylabel('Velocity, de-meaned [m/y]', color='b')\n",
    "        ax[i*2].spines.left.set_color('b')\n",
    "        ax[i*2].tick_params(axis='y', colors='b')\n",
    "        ax[i*2].set_xlim(np.datetime64('2016-01-01'), np.datetime64('2023-01-01'))\n",
    "        ax2 = ax[i*2].twinx()\n",
    "        ax2.plot(t, weather_column.values, '-c')\n",
    "        ax2.set_ylabel(column_name + ', de-meaned', color='c')\n",
    "        ax2.spines.right.set_color('c')\n",
    "        ax2.tick_params(axis='y', colors='c')    \n",
    "        # calculate cross-correlation for each year\n",
    "        years = np.arange(2016, 2023)\n",
    "        for j, year in enumerate(years):\n",
    "            # subset time series to year\n",
    "            df = pd.DataFrame(weather_column.loc[weather_column.index.year == year])\n",
    "            Ivyear = np.ravel(np.argwhere(t.astype('datetime64[Y]').astype(int) + 1970 == year))\n",
    "            df['v'] = v_clip_median_resamp_demean[Ivyear]\n",
    "            df.dropna(inplace=True)\n",
    "            # calculate Xcorr(v, term)\n",
    "            xcorr = correlate(df.values[:,1], df.values[:,0], mode='full', method='auto')\n",
    "            t_xcorr = (np.arange(0,len(xcorr)) * 2)\n",
    "            t_xcorr = t_xcorr - np.mean(t_xcorr)\n",
    "            # plot X-corr\n",
    "            color = plt.cm.viridis(j/(len(years)-1))\n",
    "            ax[i*2+1].plot(t_xcorr, xcorr, '-', color=color, label=str(year))\n",
    "            ax[i*2+1].set_xlabel('Weeks')\n",
    "            ax[i*2+1].set_ylabel('X-corr')\n",
    "            ax[i*2+1].legend(loc='lower left', bbox_to_anchor=[1.0, 0.0, 0.2, 0.2])\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "    plt.show()\n",
    "    \n",
    "    # save figure\n",
    "    fig_fn = os.path.join(figures_out_path, 'xcorr_velocity_' + column_name + '.png')\n",
    "    fig.savefig(fig_fn, dpi=300, bbox_inches='tight')\n",
    "    print('Figure saved to file:', fig_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1165b72-f546-4c43-82f5-49306eac1a2e",
   "metadata": {},
   "source": [
    "## Comparing upper and lower glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ffe8db-52b0-4ac4-b61f-046f94f0b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define velocity clip segments\n",
    "\n",
    "plt.imshow(v.isel(time=0).v.data, clim=(0,2500),\n",
    "           extent=(np.min(v.x.data), np.max(v.x.data),\n",
    "                   np.min(v.y.data), np.max(v.y.data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18cab2-6c9b-4108-918a-2e2f3d1e0e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hubbard",
   "language": "python",
   "name": "hubbard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

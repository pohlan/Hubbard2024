{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95ac7741-ef22-41e1-b027-74d90da19e73",
   "metadata": {},
   "source": [
    "# Construct surface elevation time series along the centerline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf0e484-f4ea-454b-8a6e-651b7f0c946f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ESMF'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/pseudo_base/lib/python3.12/site-packages/xesmf/util.py:8\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mesmpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mESMF\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'esmpy'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxesmf\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxe\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ScalarMappable\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pseudo_base/lib/python3.12/site-packages/xesmf/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data, util\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfrontend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Regridder, SpatialAverager\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pseudo_base/lib/python3.12/site-packages/xesmf/util.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mesmpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mESMF\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mESMF\u001b[39;00m\n\u001b[1;32m     12\u001b[0m LON_CF_ATTRS \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstandard_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdegrees_east\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     13\u001b[0m LAT_CF_ATTRS \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstandard_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdegrees_north\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ESMF'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm.auto import tqdm\n",
    "import xesmf as xe\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from shapely.geometry import LineString\n",
    "import xdem\n",
    "import pyproj\n",
    "import geoutils as gu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295538ce-c91e-458d-88bf-d802eefed19f",
   "metadata": {},
   "source": [
    "## Define paths to data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e14df-d051-4d3d-baa4-3d56228e9e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base paths\n",
    "data_path = '/Users/amyjenson/Documents/GitHub/Hubbard2024/'\n",
    "figures_out_path = os.path.join(data_path, 'figures') # where figures will be save\n",
    "h_out_path = os.path.join(data_path, 'DEMs') # where centerline elevations will be saved\n",
    "\n",
    "# Bed topography\n",
    "bed_fn = os.path.join(data_path, 'data', 'hubbard_bedrock_icebridge.tif')\n",
    "\n",
    "# Centerline\n",
    "cl_fn = os.path.join(data_path, 'data', 'center.gpkg')\n",
    "\n",
    "# Glacier boundaries \n",
    "aoi_fn = os.path.join(data_path, 'data', 'Hubbard_boundaries.shp')\n",
    "aoi_clipped_fn = os.path.join(data_path, 'RGI', 'Hubbard_boundaries_clipped.shp')\n",
    "\n",
    "# DEMs\n",
    "ifsar_fn = os.path.join(data_path, 'DEMs', 'ifsar_hubbardDEM.tif')\n",
    "oib_fns = sorted(glob.glob(os.path.join(data_path, 'DEMs', 'OIB_lidar', '*.tif')))\n",
    "arcticdem_fns = sorted(glob.glob(os.path.join(data_path, 'DEMs', 'ArcticDEM', 'mosaics', '*.tif')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c7625a-8289-4e4f-a0c0-570093048c81",
   "metadata": {},
   "source": [
    "## Coregister DEMs to IFSAR DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12fc60b-e5fa-40f0-a74c-fced3f44cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Load IFSAR DEM\n",
    "# load IFSAR DEM in AK albers projection\n",
    "ifsar = xdem.DEM(ifsar_fn)\n",
    "# tell XDEM what vertical projection it's in\n",
    "ifsar.set_vcrs(pyproj.CRS(\"EPSG:5703\"))\n",
    "# set vcrs from geoid to ellipsoid\n",
    "ifsar.to_vcrs(\"Ellipsoid\")\n",
    "\n",
    "# -----Load clipped glacier boundaries\n",
    "# Check if clipped boundaries already exists in directory\n",
    "if not os.path.exists(aoi_clipped_fn):\n",
    "    # grab bounds from IFSAR\n",
    "    xmin, xmax = ifsar.bounds.left, ifsar.bounds.right\n",
    "    ymin, ymax = ifsar.bounds.bottom, ifsar.bounds.top\n",
    "    from shapely.ops import clip_by_rect\n",
    "    # load AOI using geopandas\n",
    "    aoi = gpd.read_file(aoi_fn)\n",
    "    aoi = aoi.to_crs('EPSG:3338')\n",
    "    aoi_clipped = clip_by_rect(aoi.geometry[0], xmin, ymin, xmax, ymax)\n",
    "    aoi_clipped_gdf = gpd.GeoDataFrame(geometry=[aoi_clipped], crs='EPSG:3338')\n",
    "    # save to file\n",
    "    aoi_clipped_gdf.to_file(aoi_clipped_fn)\n",
    "    print('Clipped glacier boundaries saved to file:', aoi_clipped_fn)\n",
    "# Load as geoutils.Vector\n",
    "aoi_clipped_gu = gu.Vector(aoi_clipped_fn)\n",
    "print('Clipped glacier boundaries loaded from file.')\n",
    "# Reproject AOI to IFSAR CRS\n",
    "aoi_clipped_gu = aoi_clipped_gu.reproject(ifsar)\n",
    "\n",
    "# -----Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "dem_im = ax.imshow(ifsar.data, cmap=\"terrain\", clim=(0, 2.5e3),\n",
    "                   extent=(ifsar.bounds.left, ifsar.bounds.right, \n",
    "                           ifsar.bounds.bottom, ifsar.bounds.top))\n",
    "fig.colorbar(dem_im, ax=ax, shrink=0.5, label='Elevation [m]')\n",
    "aoi_clipped_gu.show(ax=ax, facecolor='None', edgecolor='k')\n",
    "ax.set_xlabel('Easting [m]')\n",
    "ax.set_ylabel('Northing [m]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676094cc-ed4f-4796-aed5-0c3ad8e11320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----Check if out_path exists\n",
    "if not os.path.exists(h_out_path):\n",
    "    os.mkdir(h_out_path)\n",
    "    print('Created out_path:', h_out_path)\n",
    "\n",
    "# -----Coregister DEMs\n",
    "# Concatenate list of OIB and ArcticDEM file names\n",
    "dem_fns = sorted(oib_fns + arcticdem_fns)\n",
    "# Iterate over DEM files\n",
    "for dem_fn in tqdm(dem_fns):\n",
    "    # Grab dataset and date from file name\n",
    "    if 'ArcticDEM' in os.path.basename(dem_fn):\n",
    "        dataset = 'ArcticDEM'\n",
    "        date = os.path.basename(dem_fn).split('_')[0]\n",
    "        date = f'{date[0:4]}-{date[4:6]}-{date[6:8]}'\n",
    "    elif 'Hubbard.' in dem_fn:\n",
    "        dataset = 'OIB'\n",
    "        year = dem_fn.split('Hubbard.')[1][0:4]\n",
    "        julian_day = dem_fn.split('Hubbard.' + year + '.')[1][0:3]\n",
    "        date = str(datetime.datetime.strptime(year + julian_day, '%Y%j').date())\n",
    "    elif 'Valerie.' in dem_fn:\n",
    "        dataset = 'OIB'\n",
    "        year = dem_fn.split('Valerie.')[1][0:4]\n",
    "        julian_day = dem_fn.split('Valerie.' + year + '.')[1][0:3]\n",
    "        date = str(datetime.datetime.strptime(year + julian_day, '%Y%j').date())\n",
    "    elif 'ILAKS' in dem_fn:\n",
    "        dataset = 'OIB'\n",
    "        year = dem_fn.split('ILAKS1B_')[1][0:4]\n",
    "        julian_day = dem_fn.split('ILAKS1B_' + year + '_')[1][0:3]\n",
    "        date = str(datetime.datetime.strptime(year + julian_day, '%Y%j').date())\n",
    "        \n",
    "    print(date, dataset)\n",
    "\n",
    "    # Check if coregistered DEM already exists in file\n",
    "    dem_out_fn = os.path.join(h_out_path, 'coregistered', f'{date}_{dataset}_Hubbard_coregistered.tif')\n",
    "    if os.path.exists(dem_out_fn):\n",
    "        print('Coregistered DEM already exists in directory, skipping...')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # load DEM using rasterio to extract just the first band (mean point elevations)\n",
    "        with rio.open(dem_fn) as src:\n",
    "            array = src.read(1)\n",
    "            transform = src.transform\n",
    "            crs = src.crs\n",
    "        # load DEM as xdem.DEM\n",
    "        dem = xdem.DEM.from_array(array, transform=transform, crs=crs)\n",
    "        # account for no data values\n",
    "        dem.data.data[(dem.data.data==-9999) | (dem.data.data==0) | (dem.data.data==-99999)] = np.nan\n",
    "    \n",
    "        # Reproject DEM to IFSAR CRS\n",
    "        dem = dem.reproject(ifsar)\n",
    "    \n",
    "        # Coregister DEM to IFSAR DEM\n",
    "        nuth_kaab = xdem.coreg.NuthKaab()\n",
    "        try:\n",
    "            nuth_kaab.fit(ifsar, dem) # Fit the data to a suitable x/y/z offset\n",
    "            aligned_dem = nuth_kaab.apply(dem) # Apply the transformation to the data\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        # Save coregistered DEM to file\n",
    "        aligned_dem.save(dem_out_fn, driver='GTiff', dtype='int64', nodata=-9999)\n",
    "        print('Coregistered DEM saved to file: ', dem_out_fn)\n",
    "        \n",
    "    print(' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da30ca-3df2-4acc-befb-354273088c0c",
   "metadata": {},
   "source": [
    "## Load and resample the centerline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64d61e4-eefe-4039-b560-aad56df6798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distance_vector(line):\n",
    "    x, y = line.coords.xy[0], line.coords.xy[1]\n",
    "    line_dist = np.zeros(len(line.coords.xy[0]))\n",
    "    for i in range(1, len(line.coords.xy[0])):\n",
    "        line_dist[i] = np.sqrt((x[i]-x[i-1])**2 + (y[i]-y[i-1])**2) + line_dist[i-1]\n",
    "    return line_dist\n",
    "\n",
    "def increase_linestring_resolution(line, distance=50):\n",
    "    # create initial distance vector\n",
    "    line_dist = create_distance_vector(line)\n",
    "    \n",
    "    # create new line distance vector\n",
    "    new_line_dist = np.arange(0, np.nanmax(line_dist), step=distance)\n",
    "\n",
    "    # grab x and y coordinates\n",
    "    x, y = line.coords.xy\n",
    "\n",
    "    # interpolate coordinates on new distance vector\n",
    "    new_x = np.interp(new_line_dist, line_dist, x)\n",
    "    new_y = np.interp(new_line_dist, line_dist, y)\n",
    "\n",
    "    # save as linestring\n",
    "    new_coords = list(zip(new_x, new_y))\n",
    "    new_line = LineString(new_coords)\n",
    "    \n",
    "    return new_line, new_line_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95161ac1-e0e8-42d2-8d2c-850fd859f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Load centerline\n",
    "cl = gpd.read_file(cl_fn)\n",
    "# Reproject to Alaska Albers\n",
    "cl = cl.to_crs('EPSG:3338')\n",
    "# Increase spatial resolution\n",
    "new_geom, cl_dist = increase_linestring_resolution(cl.geometry[0])\n",
    "cl_resamp = cl.copy()\n",
    "cl_resamp['geometry'] = [new_geom]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "cl_resamp.plot(ax=ax, color='m', label='Centerline')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8576b10-54ed-4a8d-8e9b-f709e3335ce7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----Sample surface elevations from DEMs\n",
    "# Check if sampled elevations already exist in file\n",
    "h_cl_fn = os.path.join(h_out_path, 'centerline_surface_elevation_timeseries.csv')\n",
    "if os.path.exists(h_cl_fn):\n",
    "    h_cl_df = pd.read_csv(h_cl_fn)\n",
    "    dates = pd.to_datetime(h_cl_df['Date'])\n",
    "    datasets = h_cl_df['Dataset']\n",
    "    h_cl = h_cl_df.iloc[:,2:].values\n",
    "    print('Centerline surface profiles loaded from file.')\n",
    "\n",
    "else:\n",
    "\n",
    "    # Grab coregistered DEM file names\n",
    "    h_fns = sorted(glob.glob(os.path.join(h_out_path, 'coregistered', '*.tif')))\n",
    "\n",
    "    # Initialize centerline surface heights\n",
    "    h_cl = np.zeros((len(h_fns), len(cl_resamp.geometry[0].coords.xy[0])))\n",
    "    dates = []\n",
    "    datasets = []\n",
    "\n",
    "    # Grab centerline x and y coordinates for convenience\n",
    "    cl_x, cl_y = cl_resamp.geometry[0].coords.xy\n",
    "    \n",
    "    # Iterate over file names\n",
    "    for i, fn in enumerate(h_fns):\n",
    "        h_xda = rxr.open_rasterio(fn)\n",
    "        dates.append(os.path.basename(fn)[0:10])\n",
    "        datasets.append(os.path.basename(fn).split('_')[1])\n",
    "        h_cl[i,:] = [h_xda.sel(x=x, y=y, method='nearest').data[0] for x,y in zip(cl_x, cl_y)]\n",
    "    \n",
    "    # Convert dates to datetimes\n",
    "    dts = pd.DatetimeIndex([np.datetime64(date) for date in dates])\n",
    "    \n",
    "    # Remove wacky and no data elevation values\n",
    "    h_cl[np.abs(h_cl) > 1e4] = np.nan\n",
    "    h_cl[h_cl==-9999] = np.nan\n",
    "\n",
    "    # Reformat as DataFrame and save to file\n",
    "    h_cl_df = pd.DataFrame({'Date': dates,\n",
    "                            'Dataset': datasets})\n",
    "    for i in range(np.shape(h_cl)[1]):\n",
    "        df = pd.DataFrame({str(cl_dist[i]): h_cl[:,i]})\n",
    "        h_cl_df = pd.concat([h_cl_df, df], axis=1)\n",
    "    \n",
    "    h_cl_df.to_csv(h_cl_fn, index=False)\n",
    "    print('Centerline surface elevations saved to file:', h_cl_fn)\n",
    "\n",
    "h_cl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8429f8fc-9d6a-4593-95f3-d3052da6365e",
   "metadata": {},
   "source": [
    "## Smooth the elevation profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10036636-381b-4665-b3ee-0a7ff80fb5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Check if smoothed surface profiles already exist in directory\n",
    "h_cl_smooth_fn = os.path.join(h_out_path, 'centerline_surface_elevation_timeseries_smooth.csv')\n",
    "if os.path.exists(h_cl_smooth_fn):\n",
    "    h_cl_smooth_df = pd.read_csv(h_cl_smooth_fn)\n",
    "    h_cl_smooth = h_cl_smooth_df.iloc[:,2:].values\n",
    "    print('Smoothed surface profiles loaded from file.')\n",
    "\n",
    "else:\n",
    "\n",
    "    # Smooth each elevation profile\n",
    "    def moving_average_smoothing(arr, window_size=5):\n",
    "        smoothed_arr = np.zeros_like(arr)\n",
    "        for i in range(arr.shape[0]):\n",
    "            smoothed_arr[i, :] = np.convolve(arr[i, :], np.ones(window_size) / window_size, mode='same')\n",
    "        return smoothed_arr\n",
    "    h_cl_smooth = moving_average_smoothing(h_cl)\n",
    "    h_cl_smooth[h_cl_smooth==0] = np.nan\n",
    "    \n",
    "    # Reformat as DataFrame and save to file\n",
    "    h_cl_smooth_df = pd.DataFrame({'Date': dates,\n",
    "                                   'Dataset': datasets})\n",
    "    for i in range(np.shape(h_cl_smooth)[1]):\n",
    "        df = pd.DataFrame({str(cl_dist[i]): h_cl_smooth[:,i]})\n",
    "        h_cl_smooth_df = pd.concat([h_cl_smooth_df, df], axis=1)\n",
    "    \n",
    "    h_cl_smooth_df.to_csv(h_cl_smooth_fn, index=False)\n",
    "    print('Smoothed centerline surface elevations saved to file:', h_cl_smooth_fn)\n",
    "\n",
    "h_cl_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6544c2c-45ed-48b0-82aa-d28a9d868028",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dece8d-5bd6-4699-ad01-0b59a339743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure\n",
    "plt.rcParams.update({'font.size':12, 'font.sans-serif':'Arial'})\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,6))\n",
    "lw=1.5\n",
    "\n",
    "# Define colormap for surface profiles\n",
    "cmap = plt.cm.twilight\n",
    "\n",
    "for i in range(len(h_fns)):\n",
    "    month = pd.DatetimeIndex(h_cl_df['Date']).month[i]\n",
    "    color = cmap((month-1)/11)\n",
    "    ax.plot(cl_dist, h_cl_smooth[i,:], '-', linewidth=lw, color=color)\n",
    "\n",
    "# Plot the colorbar\n",
    "sm = ScalarMappable(cmap=cmap)\n",
    "cbar = fig.colorbar(sm, ax=ax, location='top')\n",
    "cbar.ax.set_xticks(np.linspace(0,1,num=12))\n",
    "cbar.ax.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'June', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "\n",
    "# Adjust axes\n",
    "ax.set_xlim(1e3, 18e3)\n",
    "ax.set_xticks(np.arange(5e3, 20e3, step=5e3))\n",
    "ax.set_ylim(0, 800)\n",
    "ax.grid()\n",
    "ax.set_xlabel('Distance along centerline [m]')\n",
    "ax.set_ylabel('Elevation [m]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81a47ce-390b-495e-a9db-08a0a98e15be",
   "metadata": {},
   "source": [
    "## Assess how many observations each dataset is contributing to the elevation profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c44c00-6378-4870-874c-5c6fb4864b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = h_cl_df['Dataset'].drop_duplicates().values\n",
    "obs_df = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    h_cl_dataset = h_cl_df.loc[h_cl_df['Dataset']==dataset]\n",
    "    \n",
    "    obs = h_cl_dataset.drop(['Date', 'Dataset'], axis=1).values\n",
    "    nobs=len(obs[~np.isnan(obs)])\n",
    "    df = pd.DataFrame({'Dataset': [dataset], 'Obs.': [nobs]})\n",
    "    obs_df = pd.concat([obs_df, df])\n",
    "obs_df.reset_index(drop=True)\n",
    "obs_df.plot.bar(x='Dataset', y='Obs.', legend=False)\n",
    "plt.title('Number of centerline observations per dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f62e3a1-94e4-49fd-ac42-0774d956affc",
   "metadata": {},
   "source": [
    "## Plot monthly trends up- and down-glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ad6f5-5380-4fa3-8be2-2faae37a0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add Year and Month columns to centerline elevations df\n",
    "# h_cl_smooth_df['Year'] = pd.DatetimeIndex(h_cl_smooth_df['Date']).year\n",
    "# h_cl_smooth_df['Month'] = pd.DatetimeIndex(h_cl_smooth_df['Date']).month\n",
    "# h_cl_smooth_df['DOY'] = pd.DatetimeIndex(h_cl_smooth_df['Date']).dayofyear\n",
    "# cl_cols = [x for x in list(h_cl_smooth_df.columns) if '.0' in x]\n",
    "# cl_cols_float = np.array(cl_cols).astype(float)\n",
    "\n",
    "# # Remove the mean\n",
    "# h_cl_smooth_demean_df = h_cl_smooth_df.copy()\n",
    "# h_cl_smooth_demean_df[cl_cols] -= h_cl_smooth_demean_df[cl_cols].mean()\n",
    "# for col in cl_cols:\n",
    "#     h_cl_smooth_demean_df.loc[np.abs(h_cl_smooth_demean_df[col]) > 50, col] = np.nan\n",
    "\n",
    "# # Remove dates before 2016\n",
    "# h_cl_smooth_demean_df = h_cl_smooth_demean_df.loc[h_cl_smooth_demean_df['Year'] >= 2016].reset_index(drop=True)\n",
    "\n",
    "# # Define indices or up- and down-glacier regions\n",
    "# Iup = np.ravel(np.argwhere((cl_cols_float >= 7.5e3) & (cl_cols_float <= 8.5e3)))\n",
    "# Idown = np.ravel(np.argwhere((cl_cols_float >= 14e3) & (cl_cols_float <= 15e3)))\n",
    "# cols_up = [cl_cols[i] for i in Iup]\n",
    "# cols_down = [cl_cols[i] for i in Idown]\n",
    "\n",
    "# # Plot\n",
    "# fig, ax = plt.subplots(1, 1)\n",
    "# ax.plot(h_cl_smooth_demean_df['DOY'], h_cl_smooth_demean_df[cols_up], '.m', markersize=3, label='Up')\n",
    "# ax.plot(h_cl_smooth_demean_df['DOY'], h_cl_smooth_demean_df[cols_down], 'ob', markersize=1, label='Down')\n",
    "# # ax.legend(loc='best')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a2ba1-7d64-4e96-94e3-dae3db23ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.interpolate import splrep, BSpline\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(10,5), gridspec_kw={'width_ratios':[1,2]})\n",
    "# ax[0].plot(np.divide(cl_resamp.geometry[0].coords.xy[0], 1e3),\n",
    "#            np.divide(cl_resamp.geometry[0].coords.xy[1], 1e3), \n",
    "#            '-k', linewidth=1, label='Centerline')\n",
    "# ax[0].plot(np.divide([cl_resamp.geometry[0].coords.xy[0][i] for i in Iup], 1e3),\n",
    "#            np.divide([cl_resamp.geometry[0].coords.xy[1][i] for i in Iup], 1e3), \n",
    "#            '-m', linewidth=4, label='Up-glacier segment')\n",
    "# ax[0].plot(np.divide([cl_resamp.geometry[0].coords.xy[0][i] for i in Idown], 1e3),\n",
    "#            np.divide([cl_resamp.geometry[0].coords.xy[1][i] for i in Idown], 1e3), \n",
    "#            '-b', linewidth=4, label='Down-glacier segment')\n",
    "# ax[0].set_ylim(1200, 1210)\n",
    "# ax[0].set_xlabel('Easting [km]')\n",
    "# ax[0].set_ylabel('Northing [km]')\n",
    "\n",
    "# for i, cols in enumerate([cols_up, cols_down]):\n",
    "\n",
    "#     df = h_cl_smooth_demean_df[['DOY'] + cols].sort_values(by='DOY').dropna().reset_index(drop=True)\n",
    "#     df['Mean'] = df[cols].mean(axis=1)\n",
    "#     df['Median'] = df[cols].median(axis=1)\n",
    "    \n",
    "#     X = df['DOY']\n",
    "#     y = df['Median'].values\n",
    "#     tck = splrep(X, y, s=50)\n",
    "#     X_spline = np.arange(10,330)\n",
    "#     y_spline = BSpline(*tck)(X_spline)\n",
    "#     if i==0:\n",
    "#         color = 'm'\n",
    "#     else:\n",
    "#         color = 'b'\n",
    "#     ax[1].plot(X, y, '.', color=color)\n",
    "#     ax[1].plot(X_spline, y_spline, '-', color=color)\n",
    "# ax[1].set_xlabel('Day of year')\n",
    "# ax[1].set_ylabel('Elevation anomaly [m]')\n",
    "\n",
    "# handles, labels = ax[0].get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='upper center', ncols=3)\n",
    "\n",
    "# fig.subplots_adjust(wspace=0.3)\n",
    "# plt.show()\n",
    "\n",
    "# # Save figure\n",
    "# fig_fn = os.path.join(figures_out_path, 'centerline_surface_elevations_segments_spline.png')\n",
    "# fig.savefig(fig_fn, dpi=300, bbox_inches='tight')\n",
    "# print('Figure saved to file:', fig_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faddf75a-9d9b-47a2-9ede-f2dc9b4115b0",
   "metadata": {},
   "source": [
    "## Plot elevation anomalies from median over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813b5b9-dc37-4a12-95b7-6d8fad143546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Grab filtered surface elevation file names\n",
    "# h_out_fns = sorted(glob.glob(os.path.join(h_out_path, '*.tif')))\n",
    "# print('Loading and concatenating DEMs...')\n",
    "# i=0\n",
    "# for h_out_fn in tqdm(h_out_fns):\n",
    "#     # Grab date from file name\n",
    "#     date = os.path.basename(h_out_fn).split('_')[0]\n",
    "#     # Load DEM\n",
    "#     h_xda = rxr.open_rasterio(h_out_fn)\n",
    "#     # Convert to xarray.Dataset\n",
    "#     h_xda = h_xda.expand_dims(time=[np.datetime64(date)])\n",
    "#     h_xds_date = h_xda.to_dataset(dim='band')\n",
    "#     h_xds_date = h_xds_date.rename({1:'surface_elevation'})\n",
    "#     # Concatenate to full dataset\n",
    "#     if i==0:\n",
    "#         h_xds = h_xds_date.copy()\n",
    "#     else:\n",
    "#         h_xds = xr.concat([h_xds, h_xds_date], dim='time')\n",
    "#     i+=1\n",
    "\n",
    "# # Subtract the spatial median\n",
    "# h_diff_xds = h_xds - h_xds.median(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e062ae-4e15-4100-9079-a756ee694a3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Plot over time\n",
    "# for i in range(len(h_diff_xds.time.data)):\n",
    "#     h_diff_date_xds = h_diff_xds.isel(time=i)\n",
    "#     date = h_diff_xds.time.data[i]\n",
    "#     fig, ax = plt.subplots()\n",
    "#     h_diff_im = ax.imshow(h_diff_date_xds['surface_elevation'].data, cmap=plt.cm.RdBu, clim=(-20, 20),\n",
    "#                           extent=(np.min(h_diff_date_xds.x.data)/1e3, np.max(h_diff_date_xds.x.data)/1e3,\n",
    "#                                   np.min(h_diff_date_xds.y.data)/1e3, np.max(h_diff_date_xds.y.data)/1e3))\n",
    "#     ax.set_xlabel('Easting [km]')\n",
    "#     ax.set_ylabel('Northing [km]')\n",
    "#     ax.set_title(str(date)[0:10])\n",
    "#     fig.colorbar(h_diff_im, ax=ax, label='Elevation anomaly [m]')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bc88b0-d1cd-4fc9-9fbd-8163fe3f6025",
   "metadata": {},
   "source": [
    "## Calculate surface elevation anomalies over time with respect to IFSAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe4b71a-1258-4777-a182-dbe3bc98189a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Grab filtered surface elevation file names\n",
    "# h_out_fns = sorted(glob.glob(os.path.join(h_out_path, '*.tif')))\n",
    "# # Iterate over file names\n",
    "# i=0\n",
    "# for h_out_fn in tqdm(h_out_fns):\n",
    "#     # Grab date from file name\n",
    "#     date = os.path.basename(h_out_fn).split('_')[0]\n",
    "#     # Load DEM\n",
    "#     h_xda = rxr.open_rasterio(h_out_fn)\n",
    "#     # Subtract IFSAR elevations\n",
    "#     h_xda = h_xda - ifsar['h'].data\n",
    "#     # Convert to xarray.Dataset\n",
    "#     h_xda = h_xda.expand_dims(time=[np.datetime64(date)])\n",
    "#     h_diff_date = h_xda.to_dataset(dim='band')\n",
    "#     h_diff_date = h_diff_date.rename({1:'surface_elevation_diff_from_IFSAR'})\n",
    "#     # Add dataset dimension\n",
    "#     if 'ArcticDEM' in os.path.basename(h_out_fn):\n",
    "#         dataset = 'ArcticDEM'\n",
    "#     elif 'OIB' in os.path.basename(h_out_fn):\n",
    "#         dataset = 'OIB'\n",
    "#     elif 'ICESat-2' in os.path.basename(h_out_fn):\n",
    "#         dataset = 'ICESat-2'\n",
    "#     h_diff_date = h_diff_date.assign_coords(dataset=dataset)\n",
    "#     # Concatenate to full dataset\n",
    "#     if i==0:\n",
    "#         h_diff = h_diff_date.copy()\n",
    "#     else:\n",
    "#         h_diff = xr.concat([h_diff, h_diff_date], dim='time')\n",
    "#     i+=1\n",
    "# h_diff = h_diff.rio.write_crs('EPSG:3338')\n",
    "# h_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1949574a-d322-4f89-94b3-eeabe90c4951",
   "metadata": {},
   "source": [
    "## Extract surface elevation anomalies in polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04dca1f-c0e0-4c45-9c1d-6175a830db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select gates to grab anomalies\n",
    "# from shapely.geometry import Polygon, LineString\n",
    "# xmin1, xmax1 = 806e3, 809.5e3\n",
    "# ymin1, ymax1 = 1.210e6, 1.214e6\n",
    "# poly1 = Polygon([[xmin1, ymin1], [xmax1, ymin1],\n",
    "#                  [xmax1, ymax1], [xmin1, ymax1], [xmin1, ymin1]])\n",
    "# xmin2, xmax2 = 803e3, 806e3\n",
    "# ymin2, ymax2 = 1.203e6, 1.207e6\n",
    "# poly2 = Polygon([[xmin2, ymin2], [xmax2, ymin2],\n",
    "#                  [xmax2, ymax2], [xmin2, ymax2], [xmin2, ymin2]])\n",
    "\n",
    "# # plot\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(ifsar['h'], cmap='Greys_r', clim=(0,1500),\n",
    "#           extent=(np.min(ifsar.x.data)/1e3, np.max(ifsar.x.data)/1e3,\n",
    "#                   np.min(ifsar.y.data)/1e3, np.max(ifsar.y.data)/1e3))\n",
    "# ax.plot(np.divide(poly1.exterior.coords.xy[0], 1e3), \n",
    "#         np.divide(poly1.exterior.coords.xy[1], 1e3), \n",
    "#         '-', linewidth=2)\n",
    "# ax.plot(np.divide(poly2.exterior.coords.xy[0], 1e3), \n",
    "#         np.divide(poly2.exterior.coords.xy[1], 1e3),\n",
    "#         '-', linewidth=2)\n",
    "# ax.set_xlabel('Easting [km]')\n",
    "# ax.set_ylabel('Northing [km]')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39057917-8dfc-4734-9c2d-1894d9e853ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Interpolate thickness anomalies in polygons\n",
    "# h_diff_poly1 = h_diff.rio.clip([poly1]).surface_elevation_diff_from_IFSAR.median(dim=['x', 'y'], skipna=True).data\n",
    "# h_diff_poly2 = h_diff.rio.clip([poly2]).surface_elevation_diff_from_IFSAR.median(dim=['x', 'y'], skipna=True).data\n",
    "# datasets = h_diff.dataset.data\n",
    "\n",
    "# # Compile in dataframe\n",
    "# diffs_df = pd.DataFrame({'Date': h_diff.time.data,\n",
    "#                          'Dataset': datasets,\n",
    "#                          'median_diff_upglacier': h_diff_poly1,\n",
    "#                          'median_diff_downglacier': h_diff_poly2})\n",
    "# for col in ['median_diff_upglacier', 'median_diff_downglacier']:\n",
    "#     diffs_df.loc[np.abs(diffs_df[col]) > 30, col] = np.nan\n",
    "# diffs_df.set_index('Date', inplace=True)\n",
    "\n",
    "# # Add date columns\n",
    "# diffs_df['year'] = pd.DatetimeIndex(diffs_df.index).year\n",
    "# diffs_df['month'] = pd.DatetimeIndex(diffs_df.index).month\n",
    "# diffs_df['WOY'] = pd.DatetimeIndex(diffs_df.index).isocalendar().week\n",
    "# diffs_df['DOY'] = pd.DatetimeIndex(diffs_df.index).dayofyear\n",
    "\n",
    "# diffs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d6de4-1596-408f-b921-1f0795679e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----Plot\n",
    "# # define colors\n",
    "# poly1_col = 'b'\n",
    "# poly2_col = 'c'\n",
    "# # figure settings\n",
    "# lw = 1.5 # line width\n",
    "# ms = 10 # marker size\n",
    "# marker_dict = {'ArcticDEM': 'o',\n",
    "#                'OIB': 's',\n",
    "#                'ICESat-2': '^'}\n",
    "\n",
    "# plt.rcParams.update({'font.sans-serif': 'Arial', 'font.size': 12})\n",
    "# fig, ax = plt.subplots(2, 2, figsize=(10,8), gridspec_kw={'width_ratios': [1, 2]})\n",
    "# ax = ax.flatten()\n",
    "# # IFSAR map\n",
    "# ifsar_im = ax[0].imshow(ifsar['h'], cmap='Greys_r', clim=(0,1200), \n",
    "#              extent=(np.min(ifsar.x.data)/1e3, np.max(ifsar.x.data)/1e3,\n",
    "#                      np.min(ifsar.y.data)/1e3, np.max(ifsar.y.data)/1e3))\n",
    "# ax[0].plot(np.divide(poly1.exterior.coords.xy[0], 1e3), np.divide(poly1.exterior.coords.xy[1], 1e3),\n",
    "#            '-', color=poly1_col, linewidth=2)\n",
    "# ax[0].plot(np.divide(poly2.exterior.coords.xy[0], 1e3), np.divide(poly2.exterior.coords.xy[1], 1e3),\n",
    "#            '-', color=poly2_col, linewidth=2)\n",
    "# ax[0].set_xticklabels([])\n",
    "# ax[0].set_yticklabels([])\n",
    "# fig.colorbar(ifsar_im, ax=ax[0], shrink=0.6, label='Elevation [m]', orientation='horizontal')\n",
    "# ax[0].set_title('IFSAR')\n",
    "# ax[0].set_xlim(790, 810)\n",
    "# ax[0].set_ylim(1200, 1220)\n",
    "# for column, color in zip(['median_diff_upglacier', 'median_diff_downglacier'], [poly1_col, poly2_col]):\n",
    "#     # Full time series\n",
    "#     sns.scatterplot(data=diffs_df, x='Date', y=column, color=color, style='Dataset', \n",
    "#                     markers=marker_dict, ax=ax[1], legend=False)\n",
    "#     # Monthly \n",
    "#     sns.scatterplot(data=diffs_df, x='month', y=column, style='Dataset', \n",
    "#                     markers=marker_dict, color=color, legend=False)\n",
    "#     ax[3].plot(diffs_df.groupby(by='month')[column].median().index,\n",
    "#                diffs_df.groupby(by='month')[column].median(), \n",
    "#                '-', color=color, linewidth=lw)\n",
    "\n",
    "\n",
    "# ax[1].set_ylabel('meters')\n",
    "# ax[1].grid()\n",
    "# ax[1].set_ylim(0, 30)\n",
    "# ax[3].set_ylabel('meters')\n",
    "# ax[3].set_ylim(0, 30)\n",
    "# ax[3].grid()\n",
    "# # plot dummy points for legend\n",
    "# for dataset, marker in zip(marker_dict.keys(), marker_dict.values()):\n",
    "#     ax[3].plot(-10, -10, marker, markersize=ms, color='k', label=dataset)\n",
    "# ax[3].plot(-10, -10, '-k', linewidth=lw, label='Monthly median')\n",
    "# handles, labels = ax[3].get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='lower left', bbox_to_anchor=[0.07, 0.3, 0.3, 0.3])\n",
    "# ax[3].set_xlim(0, 13)\n",
    "# ax[3].set_xticks(np.arange(1,13))\n",
    "# ax[3].set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "#                        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "# ax[2].remove()\n",
    "    \n",
    "# fig.suptitle('Surface elevation difference from IFSAR DEM')\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # save figure\n",
    "# fig_fn = os.path.join(figures_out_path, 'surface_elevation_anomaly_regions_datasets.png')\n",
    "# fig.savefig(fig_fn, dpi=250, bbox_inches='tight')\n",
    "# print('Figure saved to file:', fig_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78266358-7d51-438c-a1ee-bf088d1915a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot with colors distinguishing years\n",
    "\n",
    "# fig, ax = plt.subplots(3, 2, figsize=(12,10), gridspec_kw={'width_ratios': [1,2]})\n",
    "# ax = ax.flatten()\n",
    "# # IFSAR map\n",
    "# ifsar_im = ax[0].imshow(ifsar['h'], cmap='Greys_r', clim=(0,1200), \n",
    "#              extent=(np.min(ifsar.x.data)/1e3, np.max(ifsar.x.data)/1e3,\n",
    "#                      np.min(ifsar.y.data)/1e3, np.max(ifsar.y.data)/1e3))\n",
    "# ax[0].plot(np.divide(poly1.exterior.coords.xy[0], 1e3), np.divide(poly1.exterior.coords.xy[1], 1e3),\n",
    "#            '-', color=poly1_col, linewidth=2)\n",
    "# ax[0].plot(np.divide(poly2.exterior.coords.xy[0], 1e3), np.divide(poly2.exterior.coords.xy[1], 1e3),\n",
    "#            '-', color=poly2_col, linewidth=2)\n",
    "# ax[0].set_xticklabels([])\n",
    "# ax[0].set_yticklabels([])\n",
    "# fig.colorbar(ifsar_im, ax=ax[0], shrink=0.6, label='Elevation [m]', orientation='horizontal')\n",
    "# ax[0].set_title('IFSAR')\n",
    "# ax[0].set_xlim(790, 810)\n",
    "# ax[0].set_ylim(1200, 1220)\n",
    "# # Upglacier\n",
    "# up_im = sns.scatterplot(data=diffs_df, x='month', y='median_diff_upglacier', style='Dataset', \n",
    "#                         markers=marker_dict, hue='year', palette='viridis', ax=ax[1])\n",
    "# ax[1].set_title('Upglacier')\n",
    "# ax[1].grid()\n",
    "# sns.move_legend(up_im, loc='lower left', bbox_to_anchor=[-0.55, -1.5, 0.2, 0.2])\n",
    "# ax[1].set_xticks(np.arange(1,13))\n",
    "# ax[1].set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "#                        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "# ax[1].set_xlabel('')\n",
    "# # Downglacier\n",
    "# sns.scatterplot(data=diffs_df, x='month', y='median_diff_downglacier', style='Dataset', \n",
    "#                 markers=marker_dict, hue='year', palette='viridis', ax=ax[3], legend=False)\n",
    "# ax[3].set_xlabel('')\n",
    "# ax[3].set_xticks(np.arange(1,13))\n",
    "# ax[3].set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "#                        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "# ax[3].set_title('Downglacier')\n",
    "# ax[3].grid()\n",
    "# # Upglacier - downglacier\n",
    "# diffs_df['median_diff_upglacier-downglacier'] = diffs_df['median_diff_upglacier'] - diffs_df['median_diff_downglacier']\n",
    "# # for i, year in enumerate(diffs_df['year'].drop_duplicates().values):\n",
    "# #     diffs_year = diffs_df.loc[diffs_df['year']==year]\n",
    "# #     ax[5].plot(diffs_year['month'], diffs_year['median_diff_upglacier-downglacier'], \n",
    "# #                '.-', color=plt.cm.viridis(i/len(diffs_df['year'].drop_duplicates().values)))\n",
    "# sns.scatterplot(data=diffs_df, x='month', y='median_diff_upglacier-downglacier', style='Dataset', \n",
    "#                 markers=marker_dict, hue='year', palette='viridis', ax=ax[5], legend=False)\n",
    "# ax[5].set_xlabel('Month')\n",
    "# ax[5].set_xticks(np.arange(1,13))\n",
    "# ax[5].set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "#                        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "# ax[5].grid()\n",
    "# ax[5].set_title('Upglacier - Downglacier')\n",
    "\n",
    "# for axis in [ax[1], ax[3], ax[5]]:\n",
    "#     axis.set_ylabel('meters')\n",
    "# ax[2].remove()\n",
    "# ax[4].remove()\n",
    "# fig.subplots_adjust(hspace=0.3)\n",
    "# plt.show()\n",
    "\n",
    "# # Save figure\n",
    "# fig_fn = os.path.join(figures_out_path, 'surface_elevation_anomaly_regions_years.png')\n",
    "# fig.savefig(fig_fn, dpi=250, bbox_inches='tight')\n",
    "# print('Figure saved to file:', fig_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac498c-3955-4e1c-9d06-b264ddabd755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# # sample surface anomalies along centerline\n",
    "# cl_diffs = np.array([h_diff.sel(x=x.coords.xy[0][0], y=x.coords.xy[1][0], method='nearest').surface_elevation_diff_from_IFSAR.data \n",
    "#                      for x in cl_gpd.geometry])\n",
    "# cl_diffs[np.abs(cl_diffs) > 100] = np.nan\n",
    "\n",
    "# # Smooth\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12,6))\n",
    "# for i in range(len(h_diff.time.data)):\n",
    "#     ax.plot(np.divide(cl_gpd['cngmeters'], 1e3), cl_diffs[:,i], \n",
    "#             '-', color=plt.cm.viridis(i/len(h_diff.time.data)), label=h_diff.time.data[i])\n",
    "# # ax.legend()\n",
    "# ax.set_xlabel('Distance along centerline [km]')\n",
    "# ax.set_ylabel('Elevation difference w.r.t. IFSAR')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b60dd72-d69a-4934-863d-09e0d544b450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a058745d-0ed6-4847-b75d-7caeb7528411",
   "metadata": {},
   "source": [
    "# Calculate some cross-correlations in time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64769615-8877-41e5-91df-c02c91f594f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "from scipy.signal import correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953a9c43-75e4-43a6-be06-d06260c063c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/raineyaberle/Research/Hubbard/'\n",
    "figures_out_path = os.path.join(data_path, 'figures')\n",
    "\n",
    "# Load velocity\n",
    "v_fn = os.path.join(data_path, 'velocity', 'Hubbard_5eminus5.nc')\n",
    "v = xr.open_dataset(v_fn)\n",
    "v = v.rio.write_crs('EPSG:3413')\n",
    "v = v.rio.reproject('EPSG:3338') # reproject to Alaska Albers\n",
    "v['v'] = np.sqrt(v['vx']**2 + v['vy']**2) \n",
    "# Convert units from m/yr to m/d\n",
    "v = v / 365\n",
    "\n",
    "# Load terminus\n",
    "term_fn = os.path.join(data_path, 'terminus', 'terminus_position_smooth.csv')\n",
    "term = pd.read_csv(term_fn)\n",
    "term['Date'] = pd.to_datetime(term['Date'])\n",
    "term.set_index('Date', inplace=True)\n",
    "# add mean column\n",
    "term['mean'] = term.mean(axis=1)\n",
    "\n",
    "# Air temperature\n",
    "air_fn = os.path.join(data_path, 'weather', 'wx_Haenke_2014_2022_nogap.csv')\n",
    "air = pd.read_csv(air_fn)\n",
    "# Remove rows with no dates\n",
    "Ikeep = [i for i in range(len(air)) if type(air['GMT'].values[i])==str]\n",
    "air = air.iloc[Ikeep].reset_index(drop=True)\n",
    "air.rename(columns={'GMT':'Date', 'Temp-AVG': 'AirTemp_Haenke'}, inplace=True)\n",
    "air = air[['Date', 'AirTemp_Haenke']]\n",
    "air['Date'] = pd.to_datetime(air['Date'])\n",
    "# Resample to mean daily values\n",
    "air.set_index('Date', inplace=True)\n",
    "air = air.resample(pd.Timedelta('1D')).mean()\n",
    "air.reset_index(inplace=True)\n",
    "\n",
    "# Precipitation\n",
    "pr_fn = os.path.join(data_path, 'weather', 'Yakutat_2000_2023.csv')\n",
    "pr = pd.read_csv(pr_fn)\n",
    "pr['Date_Time'] = pd.to_datetime(pr['Date_Time'])\n",
    "pr.rename(columns={'Date_Time':'Date', 'precip_accum_24_hour_set_1':'Precip_Yakutat'}, inplace=True)\n",
    "pr = pr[['Date', 'Precip_Yakutat']]\n",
    "pr.set_index('Date', inplace=True)\n",
    "pr = pr.resample('1D').mean()\n",
    "pr.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101c7a64-d14d-4b87-82d9-76f875976b76",
   "metadata": {},
   "source": [
    "## Sample upglacier and downglacier velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df9f823-2df5-4a40-b6dd-61db0e289cf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pick a couple points\n",
    "p1 = [808e3, 1212e3]\n",
    "p2 = [800e3, 1202e3]\n",
    "\n",
    "# Calculate the mean at each point over time\n",
    "v1 = v.sel(x=p1[0], y=p1[1], method='nearest')\n",
    "v1 = xr.where(v1 > 15, np.nan, v1)\n",
    "v2 = v.sel(x=p2[0], y=p2[1], method='nearest')\n",
    "v2 = xr.where(v2 > 15, np.nan, v2)\n",
    "\n",
    "# Normalize from 0 to 1\n",
    "v1_norm =  (v1 - np.min(v1)) / (np.max(v1) - np.min(v1))\n",
    "v2_norm =  (v2 - np.min(v2)) / (np.max(v2) - np.min(v2))\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,4), gridspec_kw={'width_ratios': [1, 2]})\n",
    "ax = ax.flatten()\n",
    "      \n",
    "v_im = ax[0].imshow(v.mean(dim='time').v.data, cmap='Greys_r', clim=(0,10),\n",
    "                    extent=(np.min(v.x.data)/1e3, np.max(v.x.data)/1e3, \n",
    "                            np.min(v.y.data)/1e3, np.max(v.y.data)/1e3))\n",
    "ax[0].plot(p1[0]/1e3, p1[1]/1e3, '*b', markersize=10, label='Upglacier point')\n",
    "ax[0].plot(p2[0]/1e3, p2[1]/1e3, '*c', markersize=10, label='Downglacier point')\n",
    "ax[0].legend(loc='lower left', bbox_to_anchor=[0.1, -0.6, 0.2, 0.2])\n",
    "fig.colorbar(v_im, ax=ax[0], shrink=0.6, label='Velocity [m/d')\n",
    "ax[0].set_xlabel('Easting [km]')\n",
    "ax[0].set_ylabel('Northing [km]')\n",
    "ax[1].plot(v1.time.data, v1_norm.v.data, '-b')\n",
    "ax[1].plot(v2.time.data, v2_norm.v.data, '-c')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7162179c-cd31-4dfe-85a3-5a9d65d36cbf",
   "metadata": {},
   "source": [
    "## Combine all variables into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa10b7c-9d15-4bc3-a30d-b2b75b89984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# velocity\n",
    "v_df = pd.DataFrame({'Date': v1.time.data,\n",
    "                     'Velocity': v1.v.data})\n",
    "# terminus\n",
    "term_df = term['mean'].drop_duplicates().reset_index()\n",
    "term_df.rename(columns={'mean':'Terminus'}, inplace=True)\n",
    "\n",
    "# add cumsum PDDs and precip for each year\n",
    "air['PDD'] = air['AirTemp_Haenke']\n",
    "air.loc[air['PDD'] < 0] = 0\n",
    "air['PDD_cumsum'] = air.groupby(pd.DatetimeIndex(air['Date']).year)['PDD'].cumsum()\n",
    "air['Date'] = pd.to_datetime(air['Date'])\n",
    "pr['Precip_Yakutat_cumsum'] = pr.groupby(pd.DatetimeIndex(pr['Date']).year)['Precip_Yakutat'].cumsum()\n",
    "\n",
    "# combine\n",
    "data_df = v_df.merge(term_df.merge(air.merge(pr, on='Date'), on='Date'), on='Date').set_index('Date')\n",
    "\n",
    "# resample onto weekly time scale\n",
    "data_resamp_df = data_df.resample(pd.Timedelta(1,'W')).mean()\n",
    "\n",
    "# interpolate missing values\n",
    "data_resamp_interp_df = data_resamp_df.interpolate(method='linear')\n",
    "\n",
    "# plot\n",
    "vars = list(data_df.columns)\n",
    "fig, ax = plt.subplots(len(vars), 1, figsize=(8, 4*len(vars)))\n",
    "for i, var in enumerate(vars):\n",
    "    ax[i].plot(data_resamp_interp_df[var], '-c', label='resampled, interpolated data')\n",
    "    ax[i].plot(data_df[var], '.b', label='raw data')\n",
    "    ax[i].set_title(str(var))\n",
    "    if i==0:\n",
    "        ax[i].legend(loc='upper center', ncols=2, bbox_to_anchor=[0.35, 1.1, 0.2, 0.2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ed4c4-2403-4668-9a43-322c6f89fe92",
   "metadata": {},
   "source": [
    "## Calculate cross-correlation between all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc70c64-ed45-47ad-8e44-412a05aa861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variable combinations\n",
    "combos = [['AirTemp_Haenke', 'Terminus'],\n",
    "          ['AirTemp_Haenke', 'Velocity'],\n",
    "          ['Terminus', 'Velocity']]\n",
    "\n",
    "# Define dictionary of colors for plotting variables\n",
    "colors_dict = {'Velocity': '#1b9e77',\n",
    "               'Terminus': '#d95f02',\n",
    "               'Precip_Yakutat': '#7570b3',\n",
    "               'AirTemp_Haenke': '#e7298a'}\n",
    "\n",
    "# Set up figure\n",
    "plt.rcParams.update({'font.size': 12, 'font.sans-serif': 'Arial'})\n",
    "fig, ax = plt.subplots(len(combos), 2, figsize=(12, 4*len(combos)))\n",
    "\n",
    "# Iterate over each combination of data variables\n",
    "icombo = 0\n",
    "for i in range(len(combos)):\n",
    "    # grab data variables\n",
    "    var1 = combos[i][0]\n",
    "    var2 = combos[i][1]\n",
    "    x1 = data_resamp_interp_df[var1]\n",
    "    x2 = data_resamp_interp_df[var2]\n",
    "        \n",
    "    # de-mean\n",
    "    # x1 = x1 - x1.mean()\n",
    "    # x2 = x2 - x2.mean()\n",
    "\n",
    "    # calculate cross-correlation\n",
    "    xcorr = correlate(x1, x2, mode='same')\n",
    "    Imax = np.ravel(np.argwhere(xcorr==np.nanmax(xcorr)))[0]\n",
    "\n",
    "    # grab colors for each\n",
    "    x1_col = colors_dict[var1]\n",
    "    x2_col = colors_dict[var2]\n",
    "        \n",
    "    # plot\n",
    "    ax[icombo,0].plot(x1.index, x1.values, '-', color=x1_col, label=var1)\n",
    "    ax[icombo,0].spines['left'].set_color(x1_col)\n",
    "    ax[icombo,0].tick_params(axis='y', colors=x1_col)\n",
    "    ax[icombo,0].set_ylabel(var1, color=x1_col)\n",
    "    ax[icombo,0].set_title(f'{var1} X {var2}')\n",
    "    ax2 = ax[icombo,0].twinx()\n",
    "    ax2.plot(x2.index, x2.values, '-', color=x2_col, label=var2)\n",
    "    ax2.spines['right'].set_color(x2_col)\n",
    "    ax2.tick_params(axis='y', colors=x2_col)\n",
    "    ax2.set_ylabel(var2, color=x2_col)\n",
    "    weeks = np.arange(-(len(xcorr)/2), len(xcorr)/2)\n",
    "    ax[icombo,1].plot(weeks, xcorr, '-', color='grey')\n",
    "    ax[icombo,1].plot(weeks[Imax], xcorr[Imax], '*', color='c', markersize=10)\n",
    "    ax[icombo,1].set_xlabel('Weeks')\n",
    "    ax[icombo,1].axvline(0, linestyle='-', color='k', linewidth=1)\n",
    "    ax[icombo,1].axvline(weeks[Imax], linestyle='-', color='c', linewidth=2)\n",
    "    ax[icombo,1].set_title(f'Max X-corr at {weeks[Imax]} weeks')\n",
    "    ax[icombo,1].set_yticks([])\n",
    "    ax[icombo,1].grid()\n",
    "    \n",
    "    icombo+=1\n",
    "    \n",
    "fig.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "plt.show()\n",
    "\n",
    "# save figure\n",
    "fig_fn = os.path.join(figures_out_path, 'xcorr_velocity_terminus_weather.png')\n",
    "fig.savefig(fig_fn, dpi=300, bbox_inches='tight')\n",
    "print('Figure saved to file:', fig_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5fdc93-37fe-4478-9956-c6378d8e8d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hubbard",
   "language": "python",
   "name": "hubbard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
